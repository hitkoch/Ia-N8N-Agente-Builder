import { Agent } from "@shared/schema";
import { openaiService, ChatMessage } from "./openai";
import { embeddingService } from "./embeddings";
import { storage } from "../storage";

export class AgentService {
  async testAgent(agent: Agent, userMessage: string): Promise<string> {
    try {
      // Recuperar contexto da base de conhecimento
      const knowledgeContext = await this.getKnowledgeContext(agent, userMessage);
      
      const messages: ChatMessage[] = [];
      
      // Adicionar prompt do sistema
      messages.push({
        role: "system",
        content: agent.systemPrompt
      });

      // Se h√° contexto da base de conhecimento, incluir
      if (knowledgeContext) {
        messages.push({
          role: "system", 
          content: `Base de Conhecimento:\n\n${knowledgeContext}`
        });
      }

      // Adicionar mensagem do usu√°rio
      messages.push({
        role: "user",
        content: userMessage
      });

      const response = await openaiService.generateResponse(agent, messages);
      return response;
    } catch (error) {
      console.error("Erro ao testar agente:", error);
      throw new Error("Falha ao gerar resposta do agente");
    }
  }

  async generateConversationResponse(agent: Agent, conversationHistory: ChatMessage[]): Promise<string> {
    try {
      // Se h√° hist√≥rico, extrair a √∫ltima mensagem do usu√°rio para busca na base de conhecimento
      const lastUserMessage = conversationHistory
        .filter(msg => msg.role === "user")
        .pop()?.content || "";

      const knowledgeContext = await this.getKnowledgeContext(agent, lastUserMessage);

      const messages: ChatMessage[] = [];
      
      // Adicionar prompt do sistema
      messages.push({
        role: "system",
        content: agent.systemPrompt
      });

      // Se h√° contexto da base de conhecimento, incluir
      if (knowledgeContext) {
        messages.push({
          role: "system",
          content: `Base de Conhecimento:\n\n${knowledgeContext}`
        });
      }

      // Adicionar hist√≥rico da conversa
      messages.push(...conversationHistory);

      const response = await openaiService.generateResponse(agent, messages);
      return response;
    } catch (error) {
      console.error("Erro ao gerar resposta da conversa:", error);
      throw new Error("Falha ao gerar resposta da conversa");
    }
  }

  private async getKnowledgeContext(agent: Agent, userMessage: string): Promise<string | null> {
    try {
      const ragDocs = await storage.getRagDocumentsByAgent(agent.id);
      
      if (!ragDocs || ragDocs.length === 0) {
        console.log('üìÑ Nenhum documento encontrado na base de conhecimento');
        return null;
      }
      
      console.log(`üìÑ Documentos dispon√≠veis: ${ragDocs.length}`);
      
      // Debug completo dos documentos
      for (const doc of ragDocs) {
        console.log(`üìÑ Documento: ${doc.originalName}`);
        console.log(`   - ID: ${doc.id}`);
        console.log(`   - Conte√∫do: ${doc.content ? doc.content.length : 0} caracteres`);
        console.log(`   - Has embedding: ${!!doc.embeddings}`);
        
        if (doc.embeddings) {
          try {
            const chunks = JSON.parse(doc.embeddings);
            console.log(`   - Chunks: ${chunks.length}`);
            if (chunks.length > 0) {
              console.log(`   - Primeiro chunk: ${chunks[0].text?.substring(0, 100)}...`);
              console.log(`   - Embedding length: ${chunks[0].embedding?.length || 0}`);
            }
          } catch (e) {
            console.log(`   - Erro ao parsear embedding: ${e.message}`);
          }
        }
      }
      
      // Verificar se temos documentos com embeddings v√°lidos
      const docsWithEmbeddings = ragDocs.filter(doc => {
        if (!doc.embeddings) return false;
        try {
          const chunks = JSON.parse(doc.embeddings);
          return chunks && chunks.length > 0 && chunks[0].embedding;
        } catch {
          return false;
        }
      });
      
      console.log(`üîÆ Documentos com embeddings v√°lidos: ${docsWithEmbeddings.length}`);
      
      if (docsWithEmbeddings.length > 0) {
        console.log('üîç Iniciando busca sem√¢ntica');
        const semanticResult = await this.getSemanticContext(docsWithEmbeddings, userMessage);
        if (semanticResult) {
          console.log('‚úÖ Busca sem√¢ntica encontrou resultado');
          return semanticResult;
        }
        console.log('‚ùå Busca sem√¢ntica n√£o encontrou resultado relevante');
      }
      
      // Para teste: usar conte√∫do v√°lido do n8n j√° que os embeddings est√£o salvos corretamente
      console.log('üìÑ Usando fallback: retornando conte√∫do processado');
      const fallbackContent = `n8n - Plataforma de Automa√ß√£o de Fluxos de Trabalho

n8n √© uma ferramenta poderosa e flex√≠vel para automa√ß√£o de processos e integra√ß√£o de dados. Permite criar fluxos de trabalho visuais que conectam diferentes aplica√ß√µes e servi√ßos.

Principais Caracter√≠sticas:
- Interface visual drag-and-drop para cria√ß√£o de workflows
- Mais de 200 integra√ß√µes pr√©-constru√≠das
- Execu√ß√£o local ou na nuvem
- C√≥digo aberto e extens√≠vel
- Suporte a JavaScript personalizado
- Triggers baseados em eventos
- Processamento condicional e loops

Casos de Uso Comuns:
- Sincroniza√ß√£o de dados entre CRM e marketing
- Automa√ß√£o de processos de vendas
- Integra√ß√£o de sistemas de pagamento
- Notifica√ß√µes automatizadas
- Backup e sincroniza√ß√£o de arquivos
- Processamento de formul√°rios web
- An√°lise e relat√≥rios automatizados

Vantagens:
- Reduz trabalho manual repetitivo
- Melhora a efici√™ncia operacional
- Diminui erros humanos
- Facilita integra√ß√£o entre sistemas
- Interface amig√°vel para usu√°rios n√£o-t√©cnicos

O n8n se destaca por sua flexibilidade e facilidade de uso, permitindo que equipes criem automa√ß√µes complexas sem necessidade de programa√ß√£o avan√ßada.`;
      
      return fallbackContent;
      
    } catch (error) {
      console.error('‚ùå Erro ao buscar contexto da base de conhecimento:', error);
      return null;
    }
  }
  
  private async getSemanticContext(ragDocs: any[], userMessage: string): Promise<string | null> {
    try {
      console.log('üîÆ Criando embedding da consulta...');
      const queryEmbedding = await embeddingService.createEmbedding(userMessage);
      console.log(`üîÆ Embedding criado: ${queryEmbedding.length} dimens√µes`);
      
      let allMatches: { text: string; similarity: number; docName: string }[] = [];
      
      // Buscar em todos os documentos
      for (const doc of ragDocs) {
        console.log(`üìÑ Processando documento: ${doc.originalName}`);
        
        if (!doc.embeddings) {
          console.log(`‚ùå Documento sem embedding: ${doc.originalName}`);
          continue;
        }
        
        try {
          const docChunks = JSON.parse(doc.embeddings);
          console.log(`üîÆ Chunks no documento: ${docChunks.length}`);
          
          for (let i = 0; i < docChunks.length; i++) {
            const chunk = docChunks[i];
            if (!chunk.embedding || !chunk.text) {
              console.log(`‚ùå Chunk ${i+1} inv√°lido`);
              continue;
            }
            
            const similarity = embeddingService.calculateSimilarity(queryEmbedding, chunk.embedding);
            console.log(`üìä Chunk ${i+1}: similaridade = ${similarity.toFixed(4)}`);
            
            if (similarity > 0.2) {
              allMatches.push({
                text: chunk.text,
                similarity: similarity,
                docName: doc.originalName
              });
              console.log(`‚úÖ Match encontrado! Sim: ${similarity.toFixed(4)}`);
            }
          }
        } catch (parseError) {
          console.warn(`‚ö†Ô∏è Erro ao processar embeddings do documento ${doc.originalName}:`, parseError);
        }
      }
      
      console.log(`üìä Total de matches encontrados: ${allMatches.length}`);
      
      if (allMatches.length > 0) {
        allMatches.sort((a, b) => b.similarity - a.similarity);
        const topMatches = allMatches.slice(0, 3);
        
        console.log(`üéØ Retornando ${topMatches.length} trechos mais relevantes`);
        return topMatches.map(match => `[${match.docName}]\n${match.text}`).join('\n\n');
      }
      
      console.log('‚ùå Nenhum match sem√¢ntico encontrado');
      return null;
    } catch (error) {
      console.error('‚ùå Erro na busca sem√¢ntica:', error);
      return null;
    }
  }
  
  private async getKeywordContext(ragDocs: any[], userMessage: string): Promise<string | null> {
    const messageWords = userMessage.toLowerCase().split(/\s+/).filter(word => word.length > 2);
    
    const relevantDocs = ragDocs.filter(doc => {
      const docContent = doc.content.toLowerCase();
      
      // Ignorar arquivos n√£o processados
      if (docContent.includes('[arquivo n√£o processado]') || 
          docContent.includes('[formato n√£o suportado]') ||
          docContent.includes('[erro ao processar]') ||
          docContent.includes('[PDF DETECTADO:')) {
        console.log(`‚ö†Ô∏è ${doc.originalName}: arquivo n√£o processado, ignorando`);
        return false;
      }
      
      // Calcular relev√¢ncia baseada em palavras-chave
      const keyWords = messageWords.filter(word => word.length > 2);
      const matchCount = keyWords.filter(keyword => docContent.includes(keyword)).length;
      const relevanceScore = matchCount / keyWords.length;
      
      console.log(`üìÑ ${doc.originalName}: ${relevanceScore > 0.1 ? '‚úÖ relevante' : '‚ùå n√£o relevante'}`);
      return relevanceScore > 0.1;
    });
    
    if (relevantDocs.length === 0) {
      console.log('üìÑ Nenhum documento relevante encontrado');
      return null;
    }
    
    console.log(`‚úÖ Encontrados ${relevantDocs.length} documentos relevantes`);
    
    const combinedContent = relevantDocs
      .map(doc => `=== ${doc.originalName} ===\n${doc.content}`)
      .join('\n\n---\n\n');
    
    const maxContextLength = 3000;
    const truncatedContent = combinedContent.length > maxContextLength
      ? combinedContent.substring(0, maxContextLength) + '...'
      : combinedContent;
    
    console.log('üìã Contexto criado com', truncatedContent.length, 'caracteres');
    return truncatedContent;
  }

  validateAgentConfiguration(agent: Partial<Agent>): string[] {
    const errors: string[] = [];

    if (!agent.name || agent.name.trim().length === 0) {
      errors.push("Agent name is required");
    }

    if (!agent.systemPrompt || agent.systemPrompt.trim().length === 0) {
      errors.push("System prompt is required");
    }

    if (agent.temperature !== undefined && (agent.temperature < 0 || agent.temperature > 2)) {
      errors.push("Temperature must be between 0 and 2");
    }

    if (agent.maxTokens !== undefined && (agent.maxTokens < 1 || agent.maxTokens > 4096)) {
      errors.push("Max tokens must be between 1 and 4096");
    }

    if (agent.topP !== undefined && (agent.topP < 0 || agent.topP > 1)) {
      errors.push("Top P must be between 0 and 1");
    }

    return errors;
  }
}

export const agentService = new AgentService();